# Metrics Issue - Explanation and Fix

## ğŸ” Problem

Migration completes successfully (100K rows migrated), but metrics show:
```
Rows Read: 0
Rows Written: 0
Throughput: 0.00 rows/sec
```

## ğŸ¯ Root Cause: Spark Serialization

### The Issue

1. **Metrics Object is Serialized**: When `df.foreachPartition` is called, the `Metrics` object is serialized and sent to each Spark executor.

2. **Each Executor Gets Its Own Copy**: Each executor receives a **separate copy** of the `Metrics` object. When `metrics.incrementRowsRead()` is called on an executor, it updates **that executor's copy**, not the driver's copy.

3. **Updates Never Reach Driver**: The executor-side updates are **never aggregated back** to the driver. When the job completes, the driver still has the original `Metrics` object with all zeros.

### Visual Flow

```
Driver (MainApp)
  â”œâ”€ Creates Metrics object (all zeros)
  â”œâ”€ Serializes Metrics â†’ sends to executors
  â”‚
Executor 1                    Executor 2                    Executor N
  â”œâ”€ Receives Metrics copy    â”œâ”€ Receives Metrics copy      â”œâ”€ Receives Metrics copy
  â”œâ”€ Updates: +5000 rows      â”œâ”€ Updates: +3000 rows        â”œâ”€ Updates: +2000 rows
  â””â”€ Updates stay local        â””â”€ Updates stay local         â””â”€ Updates stay local
  â”‚
Driver (after job completes)
  â””â”€ Still has original Metrics (all zeros) âŒ
```

### Why LongAdder Doesn't Help

`LongAdder` is thread-safe, but it doesn't solve the serialization problem:
- Each executor has its own `LongAdder` instance
- Updates happen on executor-side instances
- Driver never sees executor-side updates

## âœ… Solution: Spark Accumulators

Spark Accumulators are designed exactly for this use case - aggregating values from executors back to the driver.

### Changes Made

**Before (Broken):**
```scala
class Metrics extends Serializable {
  private val rowsRead = new LongAdder()  // âŒ Each executor gets its own copy
  // ...
}
```

**After (Fixed):**
```scala
class Metrics(sparkContext: SparkContext) extends Serializable {
  private val rowsRead = sparkContext.longAccumulator("migration.rowsRead")  // âœ… Aggregates across executors
  // ...
}
```

### How It Works

1. **Accumulator Registration**: Accumulators are registered with SparkContext
2. **Automatic Aggregation**: Spark automatically aggregates values from all executors
3. **Driver Access**: Driver can read the aggregated value using `.value`

### Benefits

- âœ… **Automatic Aggregation**: Values from all executors are automatically combined
- âœ… **Thread-Safe**: Built-in thread safety
- âœ… **Efficient**: Optimized for distributed computing
- âœ… **Spark-Native**: Uses Spark's built-in mechanism

## ğŸ“Š Impact

### Before Fix
- Migration: âœ… Works correctly
- Data Integrity: âœ… All rows migrated
- Metrics Display: âŒ Shows zeros
- Monitoring: âŒ Cannot track progress

### After Fix
- Migration: âœ… Works correctly
- Data Integrity: âœ… All rows migrated
- Metrics Display: âœ… Shows correct values
- Monitoring: âœ… Can track progress in real-time

## ğŸ§ª Testing

To verify the fix works:

```bash
# Run migration
spark-submit ... target/cassandra-to-yugabyte-migrator-1.0.0-SNAPSHOT.jar migration.properties

# Check metrics output - should now show:
#   Rows Read: 100000
#   Rows Written: 100000
#   Throughput: ~7000 rows/sec
```

## ğŸ“ Files Changed

1. **Metrics.scala**: Replaced `LongAdder` with `LongAccumulator`
2. **MainApp.scala**: Pass `SparkContext` to `Metrics` constructor

## ğŸ”— References

- [Spark Accumulators Documentation](https://spark.apache.org/docs/latest/rdd-programming-guide.html#accumulators)
- Similar pattern used in DataStax CDM: `CDMMetricsAccumulator`
